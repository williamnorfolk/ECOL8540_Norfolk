---
title: "Introduction to GIS"
output:
  html_document: default
  pdf_document: default
---
Install packages we will need.

**Module 1 for William Norfolk**


```{r}
library(tidyverse)
```


```{r}
# install.packages("ggplot2")
# install.packages("sp")
# install.packages("raster")
# install.packages("rgdal")
# install.packages("brew")
# install.packages("systemfonts")
# install.packages("mapview")
# install.packages("spatstat")
# install.packages("tmaptools")
# install.packages("elevatr")
# install.packages("rgbif")
# install.packages("remotes")
# remotes::install_github("Nowosad/spDataLarge")
# install.packages("spData")
# install.packages("gstat")
# install.packages("fields")
# install.packages("foreign")
# install.packages("velox")
```

What is a geographic information system (GIS)? While often thought of as means to making maps, the more basic utility of a GIS is the ability to overlay diverse spatial data layers. This is something that flat maps didn't allow us to do, and is best gotten across with an example. Let's start with tabular data on the point locations of detention basins (boring data that provides a great example!). In the process of working with this data you will be introduced to several topics (coordinate systems, vector and raster data) that we treat in more depth later.

Let's first consider coordinates. Web services like Google Maps have locations across much of the world mapped to lat-long coordinates. When these locations are polygons (e.g. Athens-Clarke County), Google Maps has an associated centroid (the approximate geographic center of the polygon) and bounding box. So we can actually retrieve the coordinates of named locations by geocoding, basically an API call. Since Google now charges, we'll use OpenStreetMap instead :)

API = applications program interface
_a set of functions and procedures allowing the creation of applications that access the features or data of an operating system, application, or other service_

```{r}
library(tmaptools)
#call coordinates of the named location, in this case Athens based on the geocode_OSM function from tmaptools

acc<-geocode_OSM("Athens-Clarke County")
acc$coords
acc$bbox

#testing another generic example
x <- geocode_OSM("Rio de Janerio")
x$coords
x$bbox
```

I have a bunch of herbarium data on the occurrences of rare plants associated with granite outcrops in the Southeast. Unfortunately, until recently, botanists collecting these specimens did not report coordinates. Nevertheless, many times location names can be used to generate coordinates. Many names are not unique, but usually are if combined with county and state. Let's see if we can get correct coordinates for Echols Mill (now quarried) nearby in Oglethorpe county using just the place name.

```{r}
em1<-geocode_OSM("Echols Mill")
em2<-geocode_OSM("Echols Mill, Oglethorpe, Georgia")

#pretty close but not exactly the same without county and state
em1
em2
```

When we don't supply more detail, we get the centroid of Echols county in south Georgia on the Florida line. But when we do, we get the Echols Mill I had in mind.
If you're geocoding, you will definitely want to doublecheck your coordinates by overlaying them on a map of the region of interest to make sure the API is making the right associations! Below, we'll see how to overlay points on polygons to do a spatial join to collect the info you would need to check against for accuracy.

To illustrate, let's bring in a .csv that contains the point locations of detention basins in Sandy Springs, which is near Atlanta in Fulton county (http://www.fultoncountyga.gov/fcgis-geospatial-data). 

```{r}
# Bring in Sandy Springs detention basin points from Fulton County GIS website
#update path to relative folder in directory

dbasins<-read.csv("../IDEAS_Spatial_Ecology_Workshop/Stormwater_Basins__Ponds__Hosted___Sandy_Springs_Georgia.csv")

# Take a look at the data
head(dbasins)
```

Notice that there is an X and Y column giving the longitude and latitude of the location of each pond. But also a series of attributes for each pond, both categorical and continuous.

```{r}
#add for data viewing
glimpse(dbasins)
```

```{r}
# What are the categories?
# the categorical variables (factors) are:
#ConstructType-presumably the basin walling type
#BasinType-what the basin is
#BasinSurf-presumable the water basin position, either surface water or underground

unique(dbasins$BasinType)
unique(dbasins$BasinSurf)
unique(dbasins$ConstructType)
```

We can explore these attributes without considering space. How many ponds by type, whether surface or underground, and construction type?

```{r}
# Aggregate data by categories
#makes a seperate dataframe with just the three categorical variables
dbtypes<-with(dbasins,table(BasinType,BasinSurf,ConstructType)) 
dbtypes<-as.data.frame(dbtypes)
head(dbtypes)

#The resulting object shows the frequecy of all permutations of each factor level in all of the variables so you can view how many basins fall into BasinType[x], BasinSurf[y] and ConstructType[z] where x, y, and z are each factor level present in the variable. 
```

We can also graph non-spatial summaries of the attribute data.
First by categories.

```{r}
# Load graphics package
library(ggplot2)

#visualizes summary statistics determined above

# Make barplot of frequencies across categories
ggplot(data=dbtypes, aes(y=Freq,x=BasinType,fill=ConstructType)) + 
  geom_bar( stat="identity") + 
  facet_grid(~BasinSurf) + 
  labs(y = "Count") + 
  labs(x = "") + 
  theme(legend.position="bottom", 
        axis.text.x = element_text(angle = 45, hjust = 1)) #add angles to read x-axis
```

Now by categorical and continuous fields.

```{r}
# Get age
dbasins$Age<-2019-dbasins$DateCreated #calculates age by subtracting the DateCreated variable from 2019.

# Show age range by construction type 
ggplot(data=dbasins, aes(y=Age,x=ConstructType,fill=ConstructType)) + 
  geom_violin(alpha = 0.5) + coord_flip() +
  theme(legend.position="") +
  labs(x = "")
```

To make use of the spatial component of the data in R, we need to convert the table to a spatial points dataframe (SPDF). I discuss data formats in more detail in the zoom recording.

```{r}
# load sp package
library(sp) #Classes and Methods for Spatial Data Library

# First let's look at arguments for the command SpatialPointsDataFrame
?SpatialPointsDataFrame
#basically a special class of R objects for coordinate data frames
```

To convert to SPDF, we need the CORRECT descripton of the coordinate system. 

```{r}
# In this case the coordinates are lat-long so the value of the argument is

# CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")-this is the proj4string argument answer. 

#How are these designated? or is this a standard format for Lat-Long coordinates?

dbasin_pts<-SpatialPointsDataFrame(dbasins[,1:2],
              dbasins, 
              coords.nrs = numeric(0), 
              proj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
```

Now let's take a quick look to make sure the points seem okay. The plot shows basically the shape of north Fulton county which is where the points should be.

```{r}
#Neat!
plot(dbasin_pts)

```

Let's look at the description of the SPDF. Notice that we now have points that can be displayed in 2D space that also have attributes linked to them.

```{r}
dbasin_pts
```

Similar to the geocoding example above, with these spatial points, we can make API calls through R packages to acquire, for example, elevation data from the USGS Elevation Point Query Service.

```{r}
#elevatr allpws access to elevation data
library(elevatr)
dbasins_subset<-dbasin_pts[1:10,] #subset for simplicity
dbasins_subset<-get_elev_point(dbasins_subset) #assign elevation points to subset
dbasins_subset #now have elevation 
```

Now let's bring in another layer. A shapefile of subwatershed polygons from USGS (U.S. Geological Survey, National Geospatial Program, 20200505, USGS National Hydrography Dataset Best Resolution (NHD) for Hydrologic Unit (HU) 8 - 03130001 (published 20200505): U.S. Geological Survey.). I downloaded this data using the National Map viewer website (https://viewer.nationalmap.gov/advanced-viewer/).

Note that the shapefile has become the standard format in which vector GIS data is usually served. Although developed originally by ESRI, it has become non-proprietary. 
IMPORTANT to note that a single shapefile is really a set of linked files (.shp, .dbf, .shx, .prj) that are all required, but are all called by using "filename.shp".

```{r}
# Load raster package
library(raster)

# Bring in the 12 digit hydrologic units (HUC)
hucs12<- raster::shapefile("../IDEAS_Spatial_Ecology_Workshop/Hydrologic_Units_Subwatershed.shp")
```

What is the coordinate system of the hucs? Is it also lat-long (aka unprojected, aka geographic)? How can we find out?

_The coordinate system is lat-long base don the information in the project4string. We can find this information by calling the command entered below, or viewing the object from the environment and selecting_ `projargs` _dropdown to view._ 

```{r}
#view the projargs
hucs12@proj4string@projargs
# project4string = +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
# string represent lat-long (also included in syntax)
```

Now let's overlay these layers to browse the data in R. You can zoom in or out and clip on points or polygons to see the attributes.

```{r}
# Load mapview package to interactively view layers
library(mapview)

# View
mapview::mapview(dbasin_pts) + mapview::mapview(hucs12)
```

Let's add the name of the 12 digit subwatershed to the attributes of the detention basin points to allow us to look at differences between subwatersheds. This is known as a spatial join.

```{r}
# Get HUC 12 watershed name of each retention basin
dbn_hucs<-over(dbasin_pts,hucs12) #add 12 digit identifiers
head(dbn_hucs)

# Add HUC 12 name to detention basin SPDF
dbasin_pts@data<-cbind(dbasin_pts@data,dbn_hucs$HU_12_NAME)

# Let's look at the dbasin.pts attribute table now
dbasin_pts
```

Now, we can write out dbasin_pts as a shapefile that can be brought in to other GIS software and will retain the new information we have collected.

```{r}
library(raster)
#relative to data folder
shapefile(dbasin_pts,"../IDEAS_Spatial_Ecology_Workshop/dbasin_pts.shp", overwrite=T)
```

Or, the dbasin_pts spatial points data frame can be stored within a saved R workspace or .RData file. Please save this workspace so that you can load it in the next exercise.

```{r}
#drop in mapping folder
save.image("intro.RData")
```

We have just worked through a simple example of overlaying spatial data layers in order to transfer data from one layer to another. 

